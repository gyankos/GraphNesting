% !TeX root = 00_paper_entrypoint.tex


\section{Experimental Evaluations}\label{sec:nestexpeval}
Through the following experiments we want to show that our approach outperforms the same proposed coauthorship nesting scenario  on top of graph, relational, or document oriented databases. Therefore, we consider the time required to \textit{(i)}  serialize our data structure and \textit{(ii)} evaluate the query plan. In the former we compare the loading and indexing times (the time required to store and index the data structure), and in the latter  we time the query  over the previously-loaded operand. This twofold analysis is required because, in some cases, the costly creation of several indices may lead to a better query performance.

The lack of ancillary data attached to either vertices or edges ($\forall o. \omega(o)=\{\}$) allows a better comparison of query evaluation times, which are now independent from the values' representations and more tailored to evaluate both the  access time required for traversing the loaded operator and returning the nested representation.
%The query plans are evaluated with respect to the data representation where no additional data is attached to it: by doing so we compare the algorithms used within the data structures without considering the data representation costs. 
For our evaluations we choose a bibliography graph where vertices are only represented by  vertex ids and  label, and edges are represented only by both their label, and the source and target vertices' id. Such graph was generated by the gMark generator \cite{BBCFLA17} and by random sampling the Microsoft Academic Graph \cite{Tang08,Sinha15}. In the first case, a Zipf's Law distribution with parameter $2.5$ is associated to the ingoing distribution  of each \textsc{authorOf}, while a normal distribution between $0$ and $80$ is associated to its outgoing distribution; the generator was configured to generate $8$ experiments by incrementally creating a graph with vertices with a power of $10$, that is from $10$ to $10^8$. %For both datasets, each vertex represents either an \textsc{Author} or an authored \textsc{Paper} having distinct ids. The resulting graph is represented as a list of triplets: source id, edge label (author of) and target id. 
Microsoft Academic Graph operands were obtained by incrementally aggregating complete papers' egonets, so that each graph of vertex size $10^n$ is a subgraph of the  $10^m$-operands with $n<m$.


We performed our tests over a Lenovo ThinkPad P51 with a 3.00 GHz (until 4.00 GHz) Intel Xeon processor and 64 GB of RAM at 2.400 MHz. The tests were performed over a ferromagnetic Hard Disk at 5400 RPM with an NTFS File System. We evaluate THoSP using the two pattern matching queries provided in the running example. 
%Given that the secondary memory representation is a simple extension of the one used for nested graphs, we assume that our data serialization is always outperforming with repsect to graph libraries as discussed in our previous work on graph joins, where a similar graph data structure was adopted \cite{BergamiMM17}. 
We used default configurations for  \textbf{Neo4J 3.3.0}, \textbf{PostgreSQL 9.6.6} and \textbf{ArangoDB 3.2.7}, while we changed the cache buffer configurations for \textbf{Virtuoso 7.2} (as suggested in the configuration file) for 64 GB of RAM; we also kept  default multithreaded query execution plan. PostgreSQL queries were evaluated through the \texttt{psql} client and benchmarked using both \texttt{explain analyze} and \texttt{\textbackslash timing} commands; the former   allows to analyse SQL's query plans. Virtuoso was benchmarked through the Redland RDF library using directly the \texttt{librdf\_model\_query\_execute} function; SPARQL's associated query plan was analysed via Virtuoso's \texttt{explain} satement. 
%For Neo4J and PostgreSQL we kept the same default policies as depicted for  GCEA in Subsection \ref{sec:qplan}. Therefore, we must only describe the conditions under which we performed the time execution experiments for \textbf{ArangoDB}. 
AQL queries over {ArangoDB} were evaluated directly through the \texttt{arangosh} client and benchmarked using the \texttt{getExtra()} method; statements' \texttt{explain} method was used to analyse AQL's query plans. %Given that little documentation is provided with respect to the internal plan's implementations, we referred to the \texttt{explain} procedure provided by the shell itself. 
Cypher queries were evaluated using the Java API through the \texttt{execute} method of a \texttt{GraphDatabaseService} object; the \texttt{EX\-PLAIN} statement was used to analyse the query's associated query plan. Given that only binary database connections were used (e.g., no HTTP),
all the aforementioned conditions do not degradate the query evaluations. Last, given that all databases (except from Neo4J) are implemented in C/C++ and that Neo4J provided the worst overall performances, we implemented  serialization and THoSP only in C++.
Within the relational model the graph operand's edge information were  stored in one single relational table. Similar approaches are automatically used in Virtuoso for representing RDF triple stores over its relational engine. As opposed to our implementation, all the current databases do not serialize the resulting nested graph in secondary memory.



First of all, we must discuss the  loading and indexing time (Table \ref{tab:storeevaluation} and \ref{tab:storeevaluation2}). We begin with a comparison of Virtuoso and PostgreSQL, because they are both based on a traditional relational database engine using one single table to store a graph. Virtuoso  stores an RDF graph using its default format, while in PostgreSQL the graph was stored as described in Section 2.2. Given that Virtuoso is transactionless, it performed better at loading and index data for very small data sets (from $10$ to $10^3$) while, afterwards, the triple indexing time takes over on the overall performances. On the other hand, ArangoDB has not a relational data representation, and it  serializes vertices and edges as JSON objects with several primary (vertex and edge id) and secondary (edges' source and target id) indices. Given that the only data loaded into ArangoDB are the edges' labels, all the time required to store the data is the indexing time. Neo4J's serialization proves to be inefficient, mainly because there are no constraints for data duplication and we must always check if the to-be-inserted vertex already exists. Finally, our nested graph data structure creates adjacency lists directly when serializing the data, while primary indices are not used by our input data serialization, because the adjacency lists information is sufficient to join the edges in a two hop distance scenario.

Let us now consider the graph nesting time for the synthetic dataset (Table \ref{tab:querytimeeval}): albeit no specific triplet or key are associated to the stored graph, PostgreSQL appears to be more performant than Virtuoso on graph nesting. Please also note that the Virtuoso query engine rewrites the SPARQL query into SQL and, hereby, two SQL queries were performed in both cases. Since both data were represented in a similar way in secondary memory, the completely different performance between the two databases must be attributed  to an inefficient rewriting of the SPARQL query into SQL. In particular, the nested representation using JSON array for PostgreSQL proved to be more efficient than returning a full RDF graph represented by triplets, thus arguing in favour of document stores. The PostgreSQL's efficiency is attributable to the run-time indexing time of the relational tables, that is shared with ArangoDB, where the indices are created at loading time instead: in both cases a single join operation is performed, plus some (either runtime or stored) index access time. Both PostgreSQL and ArangoDB use \texttt{GROUP BY}-s to create collections of nested values, separately for both vertices and edges. As observed in the previous paragraph, no primary index is used while performing the THoSP query, and adjacency graphs are returned using the same data structure used for graph joins: one single vertex is returned alongside the set of outgoing edges. Moreover, the nesting result is not created by using \texttt{GROUP BY}-s, but by sparsely creating an index that associates the container to its members: as a result, our query plan does not generate an additional cost for sorting and collecting all the elements because the nesting is provided during the graph traversal phase. Thus, the choice of representing the nesting information as a separate index proves to be more efficient.

As a last step, we consider the graph nesting time for the real world Microsoft Academic Graph dataset (Table \ref{tab:querytimeeval2}). First of all, we observe an increased number of generated subgraphs for the same vertex operand size; the increased number of comparisons results in overall increased evaluation time. Nevertheless, the more significant discrepancy between  THoSP's evaluation time and the opposing solutions' remarks that our solution is more competitive when multiplicity increases: in particular, our solution benefits from the path join restrictions to the papers' coauthors and the absence of \texttt{GROUP BY} costs. The real data scenario also remarks that current databases and query languages have structural deficiencies concerning the implementations' spatial complexity. Except for Virtuoso which has a primary memory configuration, all the proposed solutions suffer from Out Of Memory errors: while Neo4J exhibits such problems after the 1H timeout while computing the desired result, all the remaining opponents quickly run out of memory during the indexing time. Our solution overcomes such limitations by both using an adjacency list representation in primary memory for the final result, and by avoiding \texttt{GROUP BY} costs.